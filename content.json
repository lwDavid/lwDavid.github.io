{"meta":{"title":"Site","subtitle":"","description":"","author":"David","url":"https://lwdavid.github.io","root":"/"},"pages":[],"posts":[{"title":"《机器学习方法》 第1章 机器学习及监督学习概论","slug":"机器学习方法-第1章-机器学习及监督学习概论","date":"2023-09-09T12:56:07.000Z","updated":"2023-09-09T15:14:53.930Z","comments":true,"path":"2023/09/09/机器学习方法-第1章-机器学习及监督学习概论/","link":"","permalink":"https://lwdavid.github.io/2023/09/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC1%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/","excerpt":"","text":"1.1 统计学习 学习的定义: Learning is any process by which a system improves performance from experience. ——Herbert A. Simon 机器学习的对象是数据。 机器学习由监督学习、无监督学习和强化学习等组成。 机器学习的三要素是：模型、策略、算法。 实现机器学习方法的步骤是：获得数据、确定模型、选择策略、实现算法、选择模型、进行预测或分析。 1.2 机器学习的分类 基本分类：监督学习、无监督学习、强化学习、半监督学习与主动学习。 给出了输入空间、特征空间、输出空间、实例、特征向量、联合概率分布、假设空间、状态、奖励、动作、策略、价值函数等概念的定义。 强化学习有基于策略的、基于价值的，这两种属于无模型的方法（求解策略或价值函数），此外还有有模型的方法（建模并学习问题）。 按模型分类：概率与非概率模型、线性与非线性模型、参数化与非参数化模型。 概率：决策树、朴素贝叶斯、隐马尔可夫、CRF、概率潜在语义分析、潜在狄利克雷分配、GMM。 非概率：感知机、SVM、k近邻、AdaBoost、k均值、潜在语义分析、神经网络。 线性：感知机、SVM、k近邻、k均值、潜在语义分析。 非线性：核函数SVM、AdaBoost、神经网络。 参数化：感知机、朴素贝叶斯、逻辑斯谛回归、k均值、GMM。 非参数化：决策树、SVM、AdaBoost、k近邻、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配。 按算法分类：在线学习、批量学习 数据依次到达无法存储、系统要求及时处理、数据规模很大、模式动态变化等情况需要考虑在线学习。 按技巧分类：贝叶斯学习、核方法 贝叶斯方法：主要利用贝叶斯定理。即根据获得的数据基于后验概率去估计模型，指导模型的选择。需要选择模型时就选择后验概率最大的模型，预测时就计算整个后验概率分布上的期望。和最大似然估计的差别在于，极大似然估计直接选取后验概率最大的模型和预测，贝叶斯方法则在全体上取期望。 核方法：不显式地定义低维到高维的映射，而是直接定义映射后在特征空间的内积，也就是核函数。例如{\\it x}_{\\rm 1}和{\\it x}_{\\rm 2}的内积是\\left，它们在特征空间的映射是\\varphi({\\it x}_{\\rm 1})和\\varphi({\\it x}_{\\rm 2})，内积是\\left。那么核函数{\\it K}({\\it x}_{\\rm 1},{\\it x}_{\\rm 2})就定义为{\\it K}({\\it x}_{\\rm 1},{\\it x}_{\\rm 2})=\\left。 1.3 机器学习方法的三要素 方法=模型+策略+算法 模型 假设空间F\\mathcal{F}F包含所有可能的模型：\\mathcal{F}=\\{\\it{f}|Y=f(X)\\}. 策略 考虑按照什么准测学习或选择模型。 引入损失函数{\\it L}({\\it Y}, {\\it f}({\\it X}))和风险函数{\\it R}_{\\rm exp}({\\it f})。 损失函数：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数（对数似然损失函数）等。 风险函数：模型的损失函数在整个联合分布{\\it P}({\\it X}, {\\it Y})上的期望即为风险函数，也叫期望损失。 由于整个联合分布无从得知，所以只能使用训练集上的平均损失，也就是经验风险或经验损失{\\it R}_{\\rm emp}({\\it f})。 根据大数定理，当样本容量{\\it N}\\rightarrow\\infty时有{\\it R}_{\\rm emp}({\\it f})\\rightarrow{\\it R}_{\\rm exp}({\\it f})。 监督学习有两个策略：经验风险最小化(Empirical Risk Minimization, ERM)和结构风险最小化(Structural Risk Minimization, SRM)。 经验风险最小化： \\min_{\\it f\\in\\mathcal{F}} \\frac{1}{\\it N} \\sum^{\\it N}_{i=1}{\\it L}({\\it y_i}, {\\it f}({\\it x_i})) 结构风险最小化： \\min_{\\it f\\in\\mathcal{F}} \\frac{1}{\\it N} \\sum^{\\it N}_{i=1}{\\it L}({\\it y_i}, {\\it f}({\\it x_i}))+\\lambda{\\it J}({\\it f}) 结构风险最小化在经验风险最小化的基础上添加一个正则化项（罚项）以控制模型的复杂度。 算法 即求解最优化问题的具体计算方法。 1.4 模型评估与模型选择 训练误差、测试误差。 模型的选择：过拟合（模型复杂度高，测试误差与训练误差重新形成较大差距）。 1.5 正则化与交叉验证 正则化项可采用{\\it L}_{\\rm p}-范数： \\lVert{\\it x}\\rVert_p=\\left(\\sum^{n}_{i=1}\\lvert{\\it x}_{\\rm i}\\rvert^{p}\\right)^{\\frac{1}{p}} 交叉验证： 简单交叉验证 一部分作为训练集，一部分作为验证集。 S折交叉验证 切分为S个大小相同互不相交的子集，一个作为验证集其余作为训练集，然后重复S次。 留一交叉验证 即S=N的S折交叉验证。 1.6 泛化能力 泛化误差是该模型在X×Y\\mathcal{X}\\times\\mathcal{Y}X×Y上损失函数的期望。 对二类分类问题，可以由Hoeffding不等式推导出泛化误差上界。 1.7 生成模型与判别模型 在监督学习中， 生成模型：可学习联合概率分布、收敛快、可在样本容量增加时收敛于真实模型、能应对隐变量 朴素贝叶斯、隐马尔可夫 判别模型：直接学习决策函数或条件概率分布、准确率高、可对数据进行抽象、能定义并使用特征从而简化学习问题 k近邻、感知机、决策树、逻辑斯谛回归、最大熵模型、SVM、提升方法、CRF等 1.8 监督学习应用 分类 分类器指标：准确率(Accuracy)。 二类分类：精确率(Precision)、召回率(Recall)、F1F_1F​1​​分数(F1F_1F​1​​ score)。 常用模型：k近邻、感知机、朴素贝叶斯、决策树、决策列表、逻辑斯谛回归、SVM、提升方法、贝叶斯网络、神经网络、Winnow等。 标注 指标与分类类似。 常用模型：隐马尔可夫、CRF。 回归 常用的损失函数是平方损失函数，此时可用最小二乘法(Least Squares)求解。 习题 1.1 答案 1.2","categories":[],"tags":[{"name":"机器学习方法","slug":"机器学习方法","permalink":"https://lwdavid.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}]},{"title":"test_post_2","slug":"test-post-2","date":"2023-09-09T10:57:14.000Z","updated":"2023-09-09T10:57:14.159Z","comments":true,"path":"2023/09/09/test-post-2/","link":"","permalink":"https://lwdavid.github.io/2023/09/09/test-post-2/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test_post","slug":"test-post","date":"2023-09-09T10:56:27.000Z","updated":"2023-09-09T10:56:27.406Z","comments":true,"path":"2023/09/09/test-post/","link":"","permalink":"https://lwdavid.github.io/2023/09/09/test-post/","excerpt":"","text":"","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"机器学习方法","slug":"机器学习方法","permalink":"https://lwdavid.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}]}